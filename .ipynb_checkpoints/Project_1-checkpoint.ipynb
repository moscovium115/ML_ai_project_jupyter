{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bad30af-9fe3-40e7-a110-05cf67720795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "np.random.seed(412)  # For reproducibility\n",
    "from scipy.sparse import csc_matrix, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df076b-4cf9-47c9-987d-1897a92af154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f76fff-5126-4636-8b38-8f4a47269d71",
   "metadata": {},
   "source": [
    "## Exercise 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbde284-fd70-451b-ba65-10f902596488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data features: \n",
      " ['android.permission.GET_ACCOUNTS'\n",
      " 'com.sonyericsson.home.permission.BROADCAST_BADGE'\n",
      " 'android.permission.READ_PROFILE' 'android.permission.MANAGE_ACCOUNTS'\n",
      " 'android.permission.WRITE_SYNC_SETTINGS'\n",
      " 'android.permission.READ_EXTERNAL_STORAGE'\n",
      " 'android.permission.RECEIVE_SMS'\n",
      " 'com.android.launcher.permission.READ_SETTINGS'\n",
      " 'android.permission.WRITE_SETTINGS'\n",
      " 'com.google.android.providers.gsf.permission.READ_GSERVICES'\n",
      " 'android.permission.DOWNLOAD_WITHOUT_NOTIFICATION'\n",
      " 'android.permission.GET_TASKS'\n",
      " 'android.permission.WRITE_EXTERNAL_STORAGE'\n",
      " 'android.permission.RECORD_AUDIO'\n",
      " 'com.huawei.android.launcher.permission.CHANGE_BADGE'\n",
      " 'com.oppo.launcher.permission.READ_SETTINGS'\n",
      " 'android.permission.CHANGE_NETWORK_STATE'\n",
      " 'com.android.launcher.permission.INSTALL_SHORTCUT'\n",
      " 'android.permission.android.permission.READ_PHONE_STATE'\n",
      " 'android.permission.CALL_PHONE' 'android.permission.WRITE_CONTACTS'\n",
      " 'android.permission.READ_PHONE_STATE'\n",
      " 'com.samsung.android.providers.context.permission.WRITE_USE_APP_FEATURE_SURVEY'\n",
      " 'android.permission.MODIFY_AUDIO_SETTINGS'\n",
      " 'android.permission.ACCESS_LOCATION_EXTRA_COMMANDS'\n",
      " 'android.permission.INTERNET'\n",
      " 'android.permission.MOUNT_UNMOUNT_FILESYSTEMS'\n",
      " 'com.majeur.launcher.permission.UPDATE_BADGE'\n",
      " 'android.permission.AUTHENTICATE_ACCOUNTS'\n",
      " 'com.htc.launcher.permission.READ_SETTINGS'\n",
      " 'android.permission.ACCESS_WIFI_STATE' 'android.permission.FLASHLIGHT'\n",
      " 'android.permission.READ_APP_BADGE' 'android.permission.USE_CREDENTIALS'\n",
      " 'android.permission.CHANGE_CONFIGURATION'\n",
      " 'android.permission.READ_SYNC_SETTINGS'\n",
      " 'android.permission.BROADCAST_STICKY'\n",
      " 'com.anddoes.launcher.permission.UPDATE_COUNT'\n",
      " 'com.android.alarm.permission.SET_ALARM'\n",
      " 'com.google.android.c2dm.permission.RECEIVE'\n",
      " 'android.permission.KILL_BACKGROUND_PROCESSES'\n",
      " 'com.sonymobile.home.permission.PROVIDER_INSERT_BADGE'\n",
      " 'com.sec.android.provider.badge.permission.READ'\n",
      " 'android.permission.WRITE_CALENDAR' 'android.permission.SEND_SMS'\n",
      " 'com.huawei.android.launcher.permission.WRITE_SETTINGS'\n",
      " 'android.permission.REQUEST_INSTALL_PACKAGES'\n",
      " 'android.permission.SET_WALLPAPER_HINTS'\n",
      " 'android.permission.SET_WALLPAPER'\n",
      " 'com.oppo.launcher.permission.WRITE_SETTINGS'\n",
      " 'android.permission.RESTART_PACKAGES'\n",
      " 'me.everything.badger.permission.BADGE_COUNT_WRITE'\n",
      " 'android.permission.ACCESS_MOCK_LOCATION'\n",
      " 'android.permission.ACCESS_COARSE_LOCATION'\n",
      " 'android.permission.READ_LOGS'\n",
      " 'com.google.android.gms.permission.ACTIVITY_RECOGNITION'\n",
      " 'com.amazon.device.messaging.permission.RECEIVE'\n",
      " 'android.permission.SYSTEM_ALERT_WINDOW'\n",
      " 'android.permission.DISABLE_KEYGUARD'\n",
      " 'android.permission.USE_FINGERPRINT'\n",
      " 'me.everything.badger.permission.BADGE_COUNT_READ'\n",
      " 'android.permission.CHANGE_WIFI_STATE' 'android.permission.READ_CONTACTS'\n",
      " 'com.android.vending.BILLING' 'android.permission.READ_CALENDAR'\n",
      " 'android.permission.RECEIVE_BOOT_COMPLETED'\n",
      " 'android.permission.WAKE_LOCK' 'android.permission.ACCESS_FINE_LOCATION'\n",
      " 'android.permission.BLUETOOTH' 'android.permission.CAMERA'\n",
      " 'com.android.vending.CHECK_LICENSE'\n",
      " 'android.permission.FOREGROUND_SERVICE'\n",
      " 'android.permission.BLUETOOTH_ADMIN' 'android.permission.VIBRATE'\n",
      " 'android.permission.NFC' 'android.permission.RECEIVE_USER_PRESENT'\n",
      " 'android.permission.CLEAR_APP_CACHE'\n",
      " 'com.android.launcher.permission.UNINSTALL_SHORTCUT'\n",
      " 'com.sec.android.iap.permission.BILLING'\n",
      " 'com.htc.launcher.permission.UPDATE_SHORTCUT'\n",
      " 'com.sec.android.provider.badge.permission.WRITE'\n",
      " 'android.permission.ACCESS_NETWORK_STATE'\n",
      " 'com.google.android.finsky.permission.BIND_GET_INSTALL_REFERRER_SERVICE'\n",
      " 'com.huawei.android.launcher.permission.READ_SETTINGS'\n",
      " 'android.permission.READ_SMS' 'android.permission.PROCESS_INCOMING_CALLS'\n",
      " 'Result'] \n",
      "\n",
      "0\n",
      "The # of ones and zeros: 29332 is the same as length of y 29332\n",
      "(29332, 86)\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads the data matrix X and target vector y from a CSV file\"\"\"\n",
    "   \n",
    "    # load data\n",
    "    csv_data = pd.read_csv(file_path)\n",
    "    print(f\"Data features: \\n {csv_data.columns.values} \\n\")\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    X = csv_data.iloc[:, :-1].values\n",
    "    y = csv_data.iloc[:, -1].values\n",
    "\n",
    "    print(y[2])\n",
    "\n",
    "    num_ones_or_zeros_y=len(y[y == 0])+len(y[y==1])\n",
    "    \n",
    "    print(f\"The # of ones and zeros: {num_ones_or_zeros_y} is the same as length of y {y.shape[0]}\")\n",
    "\n",
    "\n",
    "    # Convert y to Â±1 (y is in {0, 1})\n",
    "    y = np.where(y == 0, -1,1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data('data.csv')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeea053-404f-42a3-a185-e23df732d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 29332 samples and 86 features.\n",
      "Number of malicious data points: 14700\n",
      "Number of non-malicious data points: 14632\n",
      "89.01% of X's entries are 0\n"
     ]
    }
   ],
   "source": [
    "# Display data details\n",
    "print(f\"Loaded dataset with {X.shape[0]} samples and {X.shape[1]} features.\")\n",
    "print(f\"Number of malicious data points: {np.sum(y == 1)}\")\n",
    "print(f\"Number of non-malicious data points: {np.sum(y == -1)}\")\n",
    "\n",
    "sparsity = len(X[X == 0]) / X.size * 100\n",
    "print(f\"{sparsity:.2f}% of X's entries are 0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98b394-7050-4723-9f17-56ec4061ee36",
   "metadata": {},
   "source": [
    "We dont need one hot encoding since all the data is binary. the data features and many others, are binary features. Each permission is either granted (1) or not granted (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e96a474-8938-4d6a-95d6-a7e5e27d2389",
   "metadata": {},
   "source": [
    "## Exercise 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b920bf91-5047-4ade-ad82-81f6383c5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create test and training sets\n",
    "\n",
    "\n",
    "\n",
    "def split_data(X, y, r=0.5):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "    X should be in CSC (Compressed Sparse Column) format.\n",
    "    y will be returned as a dense vector.\n",
    "    r: Test size ratio (0 < r < 1).\n",
    "    \"\"\"\n",
    "    # Convert X to sparse CSC matrix (if not already sparse)\n",
    "    if not isinstance(X, csc_matrix):\n",
    "        X_sparse = csc_matrix(X)\n",
    "    else:\n",
    "        X_sparse = X\n",
    "    \n",
    "    # y is now expected to be a dense array, so no need to convert it to sparse\n",
    "    y_dense = np.array(y)\n",
    "\n",
    "    # Shuffle and split data\n",
    "    indices = np.random.permutation(X_sparse.shape[0])\n",
    "    split_index = int(X_sparse.shape[0] * (1 - r))\n",
    "\n",
    "    # Splitting X\n",
    "    X_train = X_sparse[indices[:split_index], :]\n",
    "    X_test = X_sparse[indices[split_index:], :]\n",
    "    \n",
    "    # Splitting y (kept as dense)\n",
    "    y_train = y_dense[indices[:split_index]]\n",
    "    y_test = y_dense[indices[split_index:]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Split the dataset (50/50 split)\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, r=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78627de-0449-42d0-b668-f0a72768276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c53543-b260-442d-bb67-27be3eb43788",
   "metadata": {},
   "source": [
    "## Exercise 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1a599bf-21de-400b-ab9c-781f9fbd4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classification accuracy: 39.12%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def classify(X, y, w):\n",
    "    \"\"\"Returns the number of correctly classified points using the weight vector w.\"\"\"\n",
    "    # Perform matrix-vector multiplication (X.dot(w)) and predict using the sign function\n",
    "    predictions = np.sign(X.dot(w))\n",
    "    \n",
    "    # Convert sparse vector y to dense for comparison\n",
    "    if isinstance(y, np.ndarray):  # If y is already dense\n",
    "        y_dense = y\n",
    "    else:\n",
    "        y_dense = y.toarray().flatten()  # Convert sparse matrix to dense and flatten it\n",
    "    \n",
    "    # Compare predictions with true labels and count correct classifications\n",
    "    correct = np.sum(predictions == y_dense)\n",
    "    accuracy = correct / len(y_dense)\n",
    "    \n",
    "    return correct, accuracy\n",
    "\n",
    "# Example: Try random weight vector\n",
    "w_random = np.random.randn(X_train.shape[1])  # Random weight vector of appropriate size\n",
    "correct, accuracy = classify(X_test, y_test, w_random)\n",
    "print(f\"Random classification accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044da61f-5d5a-4255-81e6-98d8107dbeb7",
   "metadata": {},
   "source": [
    "We can verify that the output makes sense for random weight vectors by calculating the  trials over N trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7b1ac5c-131d-4461-87ee-be9bd036918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy is: 0.49492976953497886\n"
     ]
    }
   ],
   "source": [
    "avg_arr=[]\n",
    "for i in range(0,100):\n",
    "    w_random = np.random.randn(X_train.shape[1])  # Random weight vector of appropriate size\n",
    "    correct,accuracy=classify(X_test,y_test,w_random)\n",
    "    avg_arr.append(accuracy)\n",
    "\n",
    "\n",
    "print(f\"average accuracy is: {np.mean(avg_arr)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c207ea-1967-4682-bc83-ef7c37d72fc1",
   "metadata": {},
   "source": [
    "As expected, we get a value around 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f09d46-7122-43a8-979e-32f67d17f8d6",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 4)\n",
    "\n",
    "$\n",
    "J(w) = \\sum_{i=1}^{n} L(y_i x_i^T w) + \\frac{\\lambda}{2} \\| w \\|^2\n",
    "$\n",
    "\n",
    "where\n",
    "$\n",
    "L(s) = \\log(1 + e^{-s})\n",
    "$\n",
    "\n",
    "Gradient for logistic regression\n",
    "\n",
    "The gradient of the logistic regression cost function with respect to \\( w \\) is:\n",
    "\n",
    "$\n",
    "\\frac{\\partial J(\\underline{\\omega})}{\\partial \\omega_j} = \\lambda \\omega_j + \\sum_{i=1}^n \\frac{-\\exp(-y_i \\underline{x}_i^T \\underline{\\omega})}{1 + \\exp(-y_i \\underline{x}_i^T \\underline{\\omega})} y_i \\underline{x}_i^T \\underline{e}_j\n",
    "$\n",
    "\n",
    "Gradient for logistic regression\n",
    "\n",
    "The gradient of the logistic regression cost function with respect to \\( w \\) is:\n",
    "\n",
    "$\n",
    "\\frac{\\partial J(w)}{\\partial w} = \\frac{1}{m} X^T \\left( \\sigma(Xw) - y \\right) + \\frac{\\lambda}{m} w\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\sigma(z)$ is the **sigmoid function**:\n",
    "\n",
    "$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$\n",
    "\n",
    "- $ X $ is the matrix of input features.\n",
    "- $ y $ is the vector of target labels.\n",
    "- $ w $ is the weight vector.\n",
    "- $ \\lambda $ is the regularization constant.\n",
    "- $ m $ is the number of training examples.\n",
    "## Exercise 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1cc5e-57af-40aa-aa58-5991a39d7160",
   "metadata": {},
   "source": [
    "\n",
    "$\n",
    "\\frac{\\partial J(W)}{\\partial w_j} = \\sum_{i=1}^{n} L(y_i, x_i^T w)\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3fc0be-65cc-491c-8a66-50333fe3ecb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (14666,) (86,) (14666,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     B \u001b[38;5;241m=\u001b[39m (big_sigma \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m y\n\u001b[1;32m     15\u001b[0m     grad \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mdot(X)\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\n\u001b[1;32m     17\u001b[0m     w \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m grad\n\u001b[1;32m     21\u001b[0m correct, accuracy \u001b[38;5;241m=\u001b[39m classify(X_test, y_test, w)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (14666,) (86,) (14666,) "
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "num_steps = 1000\n",
    "alpha = 0.01\n",
    "reg_lambda = 10\n",
    "w = np.zeros(X.shape[1])\n",
    "for step in range(num_steps):\n",
    "    big_sigma = sigmoid(X.dot(w) * y)\n",
    "    B = (big_sigma - 1) * y\n",
    "    grad = B.dot(X)\n",
    "    grad += reg_lambda * w\n",
    "    w -= alpha * grad\n",
    "\n",
    "\n",
    "\n",
    "correct, accuracy = classify(X_test, y_test, w)\n",
    "print(f\"Test set classification accuracy: {accuracy * 100:.2f}%\")\n",
    "cost = -np.sum( np.log(big_sigma) ) + 0.5*reg_lambda * w.dot(w)\n",
    "cost / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39276abd-5463-4242-a5e4-0905eb72d72a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "def logistic_regression_cost_grad(X, y, w, reg_lambda):\n",
    "    \"\"\"Calculates the cost and gradient for logistic regression.\"\"\"\n",
    "    m = len(y)\n",
    "    z = X.dot(w)\n",
    "    # z= np.dot(X,w)\n",
    "    h = sigmoid(z)\n",
    "\n",
    "    # print(\"debug\")\n",
    "    # print(np.dot(X,w))\n",
    "\n",
    "\n",
    "    # Cost function with regularization\n",
    "    cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) + (reg_lambda / (2 * m)) * np.dot(w, w)\n",
    "    cost = (-1 / m) * np.sum(np.log(sigmoid(y*z)) ) + (reg_lambda / (2 * m)) * np.dot(w, w)\n",
    "    # print(h[0])\n",
    "    # Gradient with regularization\n",
    "\n",
    "    #grad = (1 / m) *  X.transpose().dot(h-y) + (reg_lambda / m) * w\n",
    "\n",
    "\n",
    "    big_sigma = sigmoid( z * y )\n",
    "    B = (big_sigma - 1) * y\n",
    "    grad = (1 / m) *  np.dot(X, B) + (reg_lambda / m) * w\n",
    "    # grad = (1 / m) * np.dot(X.T, (h - y)) + (reg_lambda / m) * w\n",
    "\n",
    "\n",
    "    return cost, grad\n",
    "\n",
    "\n",
    "def logistic_regression(X, y, alpha, reg_lambda, num_steps):\n",
    "    \"\"\"Performs gradient descent to find the optimal weight vector for logistic regression.\"\"\"\n",
    "    # Initialize weight vector w\n",
    "    w = np.zeros(X.shape[1])\n",
    "    # X is sparse and has much less columns than rows,\n",
    "    X_sparse = csc_matrix(X)\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        cost, grad = logistic_regression_cost_grad(X_sparse, y, w, reg_lambda)\n",
    "        w -= alpha * grad  # Gradient descent update\n",
    "\n",
    "        # Optional: print progress\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Cost: {cost}\")\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "# Train logistic regression with gradient descent\n",
    "w_trained = logistic_regression(X_train, y_train, alpha=0.01, reg_lambda=10, num_steps=10000)\n",
    "\n",
    "# Evaluate performance on the test set\n",
    "correct, accuracy = classify(X_test, y_test, w_trained)\n",
    "print(f\"Test set classification accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3ad8c-aab6-4c51-93b4-33689124473c",
   "metadata": {},
   "source": [
    "### Exercise 6) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e2a3b-4860-4b50-8aa9-67dd4363e751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with fake points.\n",
    "csv_data = pd.read_csv(\"data2.csv\")\n",
    "X = csv_data.iloc[:, :-1].values\n",
    "\n",
    "# Use PCA with the number of PCA axes the same as our number of features.\n",
    "# Additionaly whiten the data, meaning dividing each column by its standard deviation.\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "# Affirming that each column has a standard deviation of 1.\n",
    "epsilon = 0.01\n",
    "assert np.all(np.abs(np.std(X_pca, axis=0) - 1) <= epsilon)\n",
    "\n",
    "# Calculate the norm of points in the whitened PCA basis.\n",
    "# Points with a large norm can be identified as potential outliers (refer to Lecture 8).\n",
    "norm = np.linalg.norm(X_pca, axis=1) \n",
    "\n",
    "# Assuming we know that 2000 fake datapoints were added, \n",
    "# find the norm threshold that is less than exactly 2000 datapoints\n",
    "sorted_norm = np.sort(norm)\n",
    "threshold = sorted_norm[-2000];\n",
    "outliers = norm > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d63cb-e4b5-4091-812c-fec6f7b6eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# One assumption we made is that the PCA coordinates\n",
    "# should be normally distributed and in fact we can see this is the case.\n",
    "plt.hist(X_pca[:, 5], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Whitened PCA Axis 5 Coordinate')\n",
    "plt.xlabel('PCA Coordinate 5 Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08cdb1-97e6-4fb1-ac51-f9211d3aaf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This visualization shows the outlier points detected by thresholding the norms \n",
    "# of the whitened data, compared to the actual fake points that were added. \n",
    "# Most of the true fake points are clustered around (-1, 0) in the\n",
    "# PCA-1 vs. PCA-2 coordinate space. We can also see that most of fake points were identified.\n",
    "# Note: We found that the true outliers were the last 2000 points of X in data2.csv.\n",
    "\n",
    "ax1 = 0\n",
    "ax2 = 1\n",
    "plt.scatter(X_pca[:,ax1], X_pca[:,ax2], c=norm)\n",
    "plt.scatter(X_pca[outliers,ax1], X_pca[outliers,ax2], c=\"red\", label=\"Detected Outliers\")\n",
    "plt.scatter(X_pca[-2000:,ax1], X_pca[-2000:,ax2],10, c=\"green\", label=\"True Outliers\")\n",
    "plt.xlabel(\"PCA Axis 1\")\n",
    "plt.ylabel(\"PCA Axis 2\")\n",
    "plt.title(\"Norms of Whitened Data in PCA Basis\")\n",
    "plt.legend()\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8134877-7474-4960-9e72-96997b9f5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake points detected vs false positive statistics.\n",
    "\n",
    "outlier_indices = np.array(np.where(outliers)).T\n",
    "number_fake_detected = np.sum(outlier_indices > X.shape[0]-2000)\n",
    "print(f\"Number of fake points detected: {number_fake_detected}\")\n",
    "print(f\"Number of real points falsely detected as fake: {2000 - number_fake_detected}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
